\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
% \PassOptionsToPackage{numbers, compress}{natbib}
% before loading nips_2016
%
% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{nips_2016}

%\usepackage{nips_2016}

% to compile a camera-ready version, add the [final] option, e.g.:
 \usepackage[final]{nips_2016}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype,color}      % microtypography

\title{AMG methods for signal processing on graphs}

% The \author macro works with any number of authors. There are two
% commands used to separate the names and addresses of multiple
% authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to
% break the lines. Using \AND forces a line break at that point. So,
% if LaTeX puts 3 of 4 authors names on the first line, and the last
% on the second line, try using \AND instead of \And before the third
% author name.

\author{ Juntuan Lin, Xiaozhe Hu and Shuchin Aeron\\
Tufts University\\
Draft: Do Not Circulate}
  %% examples of more authors
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \AND
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
%}

\begin{document}
% \nipsfinalcopy is no longer used

\maketitle

\begin{abstract}
  This project ties Algebraic Multigrid (AMG) methods with several recently proposed framework of Graph Signal Processing (GSP). Specifically we look at the problems of spectral clustering via graph filtering, termed as Compressive Spectral Clustering (CSC) and Graph Convolutional Neural Networks (G-CNN) and show that the smoothing and the coarsening (coarsening $\sim$ sampling for CSC) schemes used in these algorithms are related to AMG smoothers and pre-conditioners. Consequently we show that...  \end{abstract}

\section{Quick Action Items}

\begin{enumerate}
\item Set up Git-Hub repo for the project. \textcolor{green}{Done}.
	\item Modify the recursive computation of the low-pass filtering using the graph Laplacian for CSC and test performance on SBMs. 
	\item Do the same and test performance on Graph-CNN. \textcolor{red}{Shuchin needs to look for a small data set for testing this}
\end{enumerate}

\section{Long-term Action Items}
\begin{enumerate}
	\item Apply CSC to PPI networks and compare with DSD based clusterings. Note that PPI networks are dense. Also note that the DSD is derived using a different metric as compared to the Diffusion Mapping \cite{xx}. We believe that this only changes the \emph{effective} Laplacian for the CSC method. Need to verify. 
	\item What are the implications for AMG methods, which after all also estimate the spectral decomposition of the Lapalcian via coarsening and smoothing? This is very interesting to explore. 
\end{enumerate}


\end{document}